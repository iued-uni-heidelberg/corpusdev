{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpusdev/blob/main/Transcribe_Audio_With_Whisper_Ukrainian_UK_UA_UA_UK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuR-jeyP-An8"
      },
      "source": [
        "# âœ¨ README\n",
        "\n",
        "This is the companion Colab for the article \"[How to transcribe your audio to text, for free (with SRTs/VTTs!)](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0)\".\n",
        "\n",
        "This Colab shows how to use OpenAI's Whisper to transcribe audio and audiovisual files, and how to save that transcription as a plain text file or as a VTT/SRT caption file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“ Documentation\n",
        "\n",
        "* `input_format`: The source of the audio/video file to be transcribed\n",
        "  * `youtube`: A YouTube video\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "  * `gdrive`: A file in your Google Drive account\n",
        "    * If you select this option, you will need to allow this notebook to connect to your Google Drive account.\n",
        "    * The transcribed file(s) are saved to the same folder as the original file.\n",
        "  * `local`: A local file that you have uploaded to this Colab\n",
        "    * If you select this option, you will need to first upload the file to the Files tab (see Step 1 [here](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozMzc1MzU3)).\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "* `file`: The URL of the YouTube video or the path of the audio file to be transcribed.\n",
        "  * Example: `file = \"https://www.youtube.com/watch?v=AUDIO\"` (transcribing a YouTube video)\n",
        "  * Example: `file = \"/content/drive/My Drive/AUDIO.mp3\"` (transcribing a Google Drive file)\n",
        "  * Example: `file = \"/content/AUDIO.mp3\"` (transcribing a local file)\n",
        "* `plain`: Whether to save the transcription as a text file or not.\n",
        "* `srt`: Whether to save the transcription as an SRT file or not.\n",
        "* `vtt`: Whether to save the transcription as a VTT file or not.\n",
        "* `tsv`: Whether to save the transcription as a TSV (tab-separated values) file or not.\n",
        "* `download`: Whether to download the transcribed file(s) or not.\n"
      ],
      "metadata": {
        "id": "EjLJ6mHptbIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/9a8ed35f5f1e46a2b695/?dl=1\n",
        "!mv index.html?dl=1 SCH_T3q9b256.mp3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgGuBGHYBhcR",
        "outputId": "784e03cf-079a-4ea4-8e7d-165603f92a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-08 12:42:14--  https://heibox.uni-heidelberg.de/f/9a8ed35f5f1e46a2b695/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/c63e1652-c8c0-4015-bda4-20848acc6010/SCH_T3q9b256.mp3 [following]\n",
            "--2024-01-08 12:42:14--  https://heibox.uni-heidelberg.de/seafhttp/files/c63e1652-c8c0-4015-bda4-20848acc6010/SCH_T3q9b256.mp3\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 191371806 (183M) [audio/mp3]\n",
            "Saving to: â€˜index.html?dl=1â€™\n",
            "\n",
            "index.html?dl=1     100%[===================>] 182.51M  14.9MB/s    in 12s     \n",
            "\n",
            "2024-01-08 12:42:26 (15.6 MB/s) - â€˜index.html?dl=1â€™ saved [191371806/191371806]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://heibox.uni-heidelberg.de/f/5c4bcecdedab4310a672/?dl=1\n",
        "# !mv index.html?dl=1 SCHWARZWALDMAEDEL_T3.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ianl4GJsEHMR",
        "outputId": "1a8caf01-35bf-462f-9086-7f39d20c0e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-08 12:35:52--  https://heibox.uni-heidelberg.de/f/5c4bcecdedab4310a672/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/74ff1f5d-789a-47a5-b44e-23a18b978d3d/SCHWARZWALDMAEDEL_T3.mp4 [following]\n",
            "--2024-01-08 12:35:52--  https://heibox.uni-heidelberg.de/seafhttp/files/74ff1f5d-789a-47a5-b44e-23a18b978d3d/SCHWARZWALDMAEDEL_T3.mp4\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3087702452 (2.9G) [video/mp4]\n",
            "Saving to: â€˜index.html?dl=1â€™\n",
            "\n",
            "index.html?dl=1     100%[===================>]   2.88G  7.81MB/s    in 5m 57s  \n",
            "\n",
            "2024-01-08 12:41:49 (8.25 MB/s) - â€˜index.html?dl=1â€™ saved [3087702452/3087702452]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ğŸŒ´ Change the values in this section\n",
        "\n",
        "# @markdown Select the source of the audio/video file to be transcribed\n",
        "input_format = \"youtube\" #@param [\"youtube\", \"gdrive\", \"local\"]\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video or the path of the audio file to be transcribed\n",
        "file = \"https://www.youtube.com/watch?v=qU4uNAdejAQ\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as text file\n",
        "plain = True #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Click here if you'd like to save the transcription as an SRT file\n",
        "srt = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a VTT file\n",
        "vtt = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a TSV file\n",
        "tsv = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to download the transcribed file(s) locally\n",
        "download = True #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "fAQKStuINe3G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLoNmM0sKyIf"
      },
      "source": [
        "# ğŸ›  Set Up\n",
        "\n",
        "The blocks below install all of the necessary Python libraries (including Whisper), configures Whisper, and contains code for various helper functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¤ Dependencies"
      ],
      "metadata": {
        "id": "hfnRc8yPM79j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "bF1enPzG-qKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fde098-c333-4af5-9b07-e657a3b95dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/57.6 kB\u001b[0m \u001b[31m657.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m755.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "\n",
        "!pip install -q pytube\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ‘‹ Whisper configuration\n",
        "\n",
        "This Colab use `medium.en`, [the medium-sized, English-only](https://github.com/openai/whisper#available-models-and-languages) Whisper model.\n"
      ],
      "metadata": {
        "id": "E4eLQzNOo5_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CUDA, if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the desired model\n",
        "# model = whisper.load_model(\"medium.en\").to(DEVICE)\n",
        "model = whisper.load_model(\"medium\").to(DEVICE)"
      ],
      "metadata": {
        "id": "YCNc3EfV4EIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7aa3ff6-c5c1-4eca-b2c6-360610e8750c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42G/1.42G [00:14<00:00, 106MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ’ª YouTube helper functions\n",
        "\n",
        "Code for helper functions when running Whisper on a YouTube video."
      ],
      "metadata": {
        "id": "IvN1wRXbo-7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "def download_youtube_audio(url,  file_name = None, out_dir = \".\"):\n",
        "    \"Download the audio from a YouTube video\"\n",
        "    yt = YouTube(url)\n",
        "    if file_name is None:\n",
        "        file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
        "    yt = (yt.streams\n",
        "            .filter(only_audio = True, file_extension = \"mp4\")\n",
        "            .order_by(\"abr\")\n",
        "            .desc())\n",
        "    return yt.first().download(filename = file_name)"
      ],
      "metadata": {
        "id": "RLmwvJ3tM-CD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ Transcribing with Whisper\n",
        "\n",
        "Ultimately, calling Whisper is as easy as one line!\n",
        "* `result = model.transcribe(file)`\n",
        "\n",
        "The majority of this new `transcribe_file` function is actually just for exporting the results of the transcription as a text, VTT, or SRT file."
      ],
      "metadata": {
        "id": "ech5wPCwtO_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_file(model, file, plain, srt, vtt, tsv, download):\n",
        "    \"\"\"\n",
        "    Runs Whisper on an audio file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Whisper\n",
        "        The Whisper model instance.\n",
        "\n",
        "    file: str\n",
        "        The file path of the file to be transcribed.\n",
        "\n",
        "    plain: bool\n",
        "        Whether to save the transcription as a text file or not.\n",
        "\n",
        "    srt: bool\n",
        "        Whether to save the transcription as an SRT file or not.\n",
        "\n",
        "    vtt: bool\n",
        "        Whether to save the transcription as a VTT file or not.\n",
        "\n",
        "    tsv: bool\n",
        "        Whether to save the transcription as a TSV file or not.\n",
        "\n",
        "    download: bool\n",
        "        Whether to download the transcribed file(s) or not.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
        "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
        "    \"\"\"\n",
        "    file_path = Path(file)\n",
        "    print(f\"Transcribing file: {file_path}\\n\")\n",
        "\n",
        "    output_directory = file_path.parent\n",
        "\n",
        "    # Run Whisper\n",
        "    result = model.transcribe(file, verbose = False, language = \"uk\")\n",
        "\n",
        "    if plain:\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        print(f\"\\nCreating text file\")\n",
        "\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "    if srt:\n",
        "        print(f\"\\nCreating SRT file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if vtt:\n",
        "        print(f\"\\nCreating VTT file\")\n",
        "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "        vtt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if tsv:\n",
        "        print(f\"\\nCreating TSV file\")\n",
        "\n",
        "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
        "        tsv_writer(result, str(file_path.stem))\n",
        "\n",
        "    if download:\n",
        "        from google.colab import files\n",
        "\n",
        "        colab_files = Path(\"/content\")\n",
        "        stem = file_path.stem\n",
        "\n",
        "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
        "                print(f\"Downloading {colab_file}\")\n",
        "                files.download(str(colab_file))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "22CwQZnOtGO1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ’¬ Whisper it!\n",
        "\n",
        "This block actually calls `transcribe_file` ğŸ˜‰\n"
      ],
      "metadata": {
        "id": "CLC_tpz6tgq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if input_format == \"youtube\":\n",
        "    # Download the audio stream of the YouTube video\n",
        "    # print(f\"Downloading audio stream: {audio}\")\n",
        "    audio = download_youtube_audio(file)\n",
        "\n",
        "    # Run Whisper on the audio stream\n",
        "    result = transcribe_file(model, audio, plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"gdrive\":\n",
        "    # Authorize a connection between Google Drive and Google Colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"local\":\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)"
      ],
      "metadata": {
        "id": "ngTGllHutSfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c88c25-dc5b-4a04-bf05-5c25feba805f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing file: /content/ğŸ”´_Ğ½Ğ¾Ğ²Ğ¸Ğ½Ğ¸_Ğ½Ğ°_8_00_7_ÑÑ–Ñ‡Ğ½Ñ.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 42900/86793 [01:45<01:37, 449.60frames/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}