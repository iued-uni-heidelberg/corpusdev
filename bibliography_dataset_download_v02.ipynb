{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs0mNGWpFrENW75MCk3Ub4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpusdev/blob/main/bibliography_dataset_download_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting bibliography for the Y1600, Y1700, Y1800 periods from library catalogues"
      ],
      "metadata": {
        "id": "drKdxmEUvsEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 downloading the json dump of vd17\n",
        "This will last about 2 minutes, the command downloads 307 json files\n",
        "(such files should be generated on stage 2, see 2.1, etc. -- but there are differences between the dupm and the downloaded version)"
      ],
      "metadata": {
        "id": "mDyHA-rzvYx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://git.hab.de/beyer/vd17-dump/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqjkxzcUFmZF",
        "outputId": "bffcc93d-59b7-41ff-cd07-51c4e84298bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vd17-dump'...\n",
            "warning: redirecting to https://git.hab.de/beyer/vd17-dump.git/\n",
            "remote: Enumerating objects: 4739, done.\u001b[K\n",
            "remote: Counting objects: 100% (2862/2862), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1210/1210), done.\u001b[K\n",
            "remote: Total 4739 (delta 2202), reused 2311 (delta 1652), pack-reused 1877\u001b[K\n",
            "Receiving objects: 100% (4739/4739), 646.05 MiB | 9.57 MiB/s, done.\n",
            "Resolving deltas: 100% (4033/4033), done.\n",
            "Updating files: 100% (309/309), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we try to filter the json objects, where\n",
        "\n",
        "\"langOrig\":\"eng\",\n",
        "\n",
        "e.g., /content/vd17-dump/json/vd17-290.json\n",
        "\n",
        "\tLine  6361:   \"langOrig\":\"eng\",\n",
        "\tLine 39193:   \"langOrig\":\"eng\",\n",
        "\n",
        "and write this to a separate file\n",
        "\n",
        "(ideally we try to create a separate language file for each langOrig value)\n",
        "\n",
        "https://stackoverflow.com/questions/27189892/how-to-filter-json-array-in-python\n"
      ],
      "metadata": {
        "id": "IRmlsilJxf6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict_file = open('vd17-all.json', 'w')\n"
      ],
      "metadata": {
        "id": "W0JzS_bp2fGs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict_file_filtered = open('vd17-allEng.json', 'w')\n"
      ],
      "metadata": {
        "id": "QVV1ikijjDJS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "def readFile(SFIn):\n",
        "    output_data = []\n",
        "\n",
        "    with open(SFIn, 'r', encoding='utf-8') as input_json:\n",
        "        input_list = json.load(input_json)\n",
        "\n",
        "\n",
        "        # LLangOrig2Keep = ['eng']\n",
        "        # output_dict = [x for x in input_dict if ('langOrig' in x.keys()) and (x['langOrig'] == 'eng') ]\n",
        "        # output_dict = [x for x in input_dict if 'langOrig' in x.keys() ]\n",
        "        # results = [d for d in results if d['title'] not in titles_remove]\n",
        "        # output_dict = [d for d in input_dict if d['langOrig'] in LLangOrig2Keep]\n",
        "        for i in input_list:\n",
        "            if 'langOrig' in i:\n",
        "                output_data.append(i)\n",
        "\n",
        "\n",
        "        # output_json_string = json.dumps(output_data)\n",
        "        json.dump(output_data, output_dict_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "\n",
        "        '''\n",
        "        data = json.load(FIn)\n",
        "        for i in data:\n",
        "            print(i)\n",
        "            FOut.write(f'{i}\\n' + '\\n')\n",
        "        '''\n",
        "\n",
        "# end def readFile\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LQHEEgmOyZwl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filtByLang(SFIn):\n",
        "    with open(SFIn, 'r', encoding='utf-8') as input_json:\n",
        "        input_list = json.load(input_json)\n",
        "        # output_list = [x for x in input_list if x['langOrig'] == 'eng']\n",
        "        output_list = list(filter(lambda x: x['langOrig'] == 'eng', input_list))\n",
        "        # list(filter(lambda x: x['type'] == 1, obj))\n",
        "\n",
        "    json.dump(output_list, output_dict_file_filtered, indent=4, ensure_ascii=False)\n",
        "# end filtByLang\n"
      ],
      "metadata": {
        "id": "1mNUB6LtjIH-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readFile('/content/vd17-dump/json/vd17-290.json')"
      ],
      "metadata": {
        "id": "SpP2sBOK1xzN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict_file.flush()\n",
        "output_dict_file.close()"
      ],
      "metadata": {
        "id": "GlJmKUx62c4c"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtByLang('/content/vd17-all.json')"
      ],
      "metadata": {
        "id": "QBmGMyI1i5Tw"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6ud8Bg7jYP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class to read the directory with json files and extract the needed language\n"
      ],
      "metadata": {
        "id": "2rKnvq20ew8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class clJsonDirFindFilter(object):\n",
        "    '''\n",
        "    @author Bogdan Babych, IÜD, Heidelberg University, 2023\n",
        "    @email bogdan [dot] babych [at] iued [dot] uni-heidelberg [dot] de\n",
        "    '''\n",
        "    def __init__(self, SDirName, output_file = 'vdExtracted-all.json', findKey = 'langOrig', filtVal = 'eng'):\n",
        "        pass\n",
        "\n",
        "\n",
        "# end: class clJsonDirFindFilter"
      ],
      "metadata": {
        "id": "XkEo5ac1lhdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 setting up the environment for download xml and converting to json\n",
        "\n",
        "We will try to download again the original xml for 17, check if it agrees with Dump, and then try to download 18, etc."
      ],
      "metadata": {
        "id": "Neb7mdYzvVTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGyrrFQB_wdt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/hbeyer/pylib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pylib/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT_ARX7WCpZt",
        "outputId": "10ba2189-a006-425f-dca1-a2ddc6827849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pylib\n",
            "/content/pylib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lib import bookwheel as bw"
      ],
      "metadata": {
        "id": "24QbZcLgIrCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pickle\n",
        "from lib import sru\n",
        "from lib import isil\n",
        "from lib import xmlreader as xr\n",
        "from lib import pica"
      ],
      "metadata": {
        "id": "1Bk4apdcJmFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s04uwOlgFccA",
        "outputId": "6ff9eb30-0f28-4035-e18f-4063dfba45ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "# from lib import bookwheel as bw\n",
        "cat = bw.Catalogue\n",
        "sec = cat.get_section(2589)\n",
        "print(sec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIn7UdSkAJuR",
        "outputId": "276b653a-4105-4c17-fbd7-49c338052f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'start': 2511, 'end': 2738, 'group': 'Libri Varii', 'dateBegin': '1634', 'year': 1634, 'writer': 'Herzog August'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir xmlbibliography\n",
        "!mkdir xmlbibliographyac"
      ],
      "metadata": {
        "id": "ffhaOHSALlvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir jsonbibliography"
      ],
      "metadata": {
        "id": "1wXpb3u7M0Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUJJ1Ju5utQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 running the download script for RecordVD17"
      ],
      "metadata": {
        "id": "9OhpGVTVvBKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# import pickle\n",
        "# from lib import sru\n",
        "# from lib import isil\n",
        "# from lib import xmlreader as xr\n",
        "# from lib import pica\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# Festlegen der Speicherpfade und der Datensätze pro JSON-Datei\n",
        "# source_folder = \"{Ordner mit den PICAXML-Dateien}/\"\n",
        "source_folder = \"/content/xmlbibliography/\"\n",
        "# source_folder_ac = \"{Ordner mit den PICAXML-Dateien für Gesamtaufnahmen mehrbändiger Werke (Ac-Sätze)}/\"\n",
        "source_folder_ac = \"/content/xmlbibliography/\"\n",
        "# target_folder = \"{Ordner zum Speichern der JSON-Dateien}/\"\n",
        "target_folder = \"/content/jsonbibliography/\"\n",
        "size = 1000\n",
        "limit = 350000\n",
        "\n",
        "# Laden der Ac-Sätze und Extrahieren der Gattungsbegriffe\n",
        "req = sru.Request_VD17()\n",
        "num = req.prepare(\"pica.bbg=Ac*\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder_ac)\n",
        "\n",
        "res = {}\n",
        "reader = xr.DownloadReader(source_folder_ac, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "for count, node in enumerate(reader):\n",
        "    rec = pica.RecordVD17(node)\n",
        "    gatt = [gat for gat in rec.gatt]\n",
        "    if gatt == []:\n",
        "        continue\n",
        "    res[rec.ppn] = gatt\n",
        "    if count > 100000:\n",
        "        break\n",
        "\n",
        "with open('gattungen-ac', 'wb') as file:\n",
        "    pickle.dump(res, file)\n",
        "\n",
        "# Download der PICA-XML-Daten\n",
        "req = sru.Request_VD17()\n",
        "num = req.prepare(\"pica.bbg=(Aa* or Af*)\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder)\n",
        "\n",
        "# Auslesen und Abspeichern in JSON\n",
        "with open('gattungen-ac','rb') as file:\n",
        "    gatt_ac = pickle.load(file)\n",
        "\n",
        "reader = xr.DownloadReader(source_folder, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "content = []\n",
        "fnn = []\n",
        "setn = 1\n",
        "count = 0\n",
        "\n",
        "for no, node in enumerate(reader):\n",
        "    rec = pica.RecordVD17(node)\n",
        "    if rec.get_rec_type() in [\"Teilband\", \"Teilband mit eigenem Titel\"]:\n",
        "        try:\n",
        "            rec.gatt = gatt_ac[rec.ppn_sup]\n",
        "        except:\n",
        "            logging.info(f\"Keine Gattungsbegriffe bei PPN {rec.ppn_sup}\")\n",
        "    content.append(rec)\n",
        "    count += 1\n",
        "    if count >= size:\n",
        "        recl = pica.RecordList(content)\n",
        "        fn = f\"vd17-{str(setn).zfill(3)}\"\n",
        "        recl.to_json(target_folder + fn)\n",
        "        content = []\n",
        "        setn += 1\n",
        "        count = 0\n",
        "    if no > limit:\n",
        "        break\n",
        "if content != []:\n",
        "    recl = pica.RecordList(content)\n",
        "    fn = f\"vd17-{str(setn).zfill(3)}\"\n",
        "    recl.to_json(target_folder + fn)\n"
      ],
      "metadata": {
        "id": "7F82KoohI6ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing commands - to be removed"
      ],
      "metadata": {
        "id": "iCJr9dNqu2TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd xmlbibliography/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qirpT0peL1h7",
        "outputId": "c767ddfe-a3b7-47f6-c845-a6b8a3f0cf6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/xmlbibliography\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB_MnmB_ASw5",
        "outputId": "309abc9c-d9de-468d-fb7b-7622b63eab55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"$/env/python\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s86IcciVHZW7",
        "outputId": "12ba24dc-e6e1-4da7-f7a3-b96f1ad9c31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PATH=\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPZelF_WIFWJ",
        "outputId": "27baf29e-7fc7-40ce-bbb1-23a5a86bb757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PATH=\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIiTbUU7Cm-2",
        "outputId": "5ee0b92e-2c0a-485d-97a7-0462d4dbb27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python:/content/pylib/lib/:/content/pylib/lib/bookwheel.py\"\n",
        "# !PYTHONPATH=. ./comet/cli/score.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfHI8zshAZc_",
        "outputId": "dcd3f04e-9b97-4428-872b-0ffc6155f40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python:/content/pylib/lib/:/content/pylib/lib/bookwheel.py\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!pwd"
      ],
      "metadata": {
        "id": "7QNOb_ahFZZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1049d3-88b3-41a4-d487-e97c1a90a79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://sru.k10plus.de/vd17?version=2.0&operation=searchRetrieve&query=pica.bbg=%28Aa*%20or%20Af*%29&maximumRecords=500&startRecord=1&recordSchema=picaxml"
      ],
      "metadata": {
        "id": "HAxwIMRYL4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv vd17?version=2.0 vd17_500.xml"
      ],
      "metadata": {
        "id": "D3xzAOeVMOlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDvJzrJVMWIG",
        "outputId": "1953d3b1-dbad-4568-c859-4ecb2ce5d003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    }
  ]
}