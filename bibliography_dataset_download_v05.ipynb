{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx+Ub5vXmlk5Gt34BJGTMR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpusdev/blob/main/bibliography_dataset_download_v05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting bibliography for the Y1600, Y1700, Y1800 periods from library catalogues"
      ],
      "metadata": {
        "id": "drKdxmEUvsEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 downloading the json dump of vd17\n",
        "This will last about 2 minutes, the command downloads 307 json files\n",
        "(such files should be generated on stage 2, see 2.1, etc. -- but there are differences between the dupm and the downloaded version)"
      ],
      "metadata": {
        "id": "mDyHA-rzvYx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://git.hab.de/beyer/vd17-dump/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqjkxzcUFmZF",
        "outputId": "afa10ea6-c8bf-4d3c-d91c-37bc8a8a06f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vd17-dump'...\n",
            "warning: redirecting to https://git.hab.de/beyer/vd17-dump.git/\n",
            "remote: Enumerating objects: 4739, done.\u001b[K\n",
            "remote: Counting objects: 100% (2862/2862), done.\u001b[K\n",
            "remote: Compressing objects: 100% (660/660), done.\u001b[K\n",
            "remote: Total 4739 (delta 2202), reused 2862 (delta 2202), pack-reused 1877\u001b[K\n",
            "Receiving objects: 100% (4739/4739), 646.03 MiB | 18.37 MiB/s, done.\n",
            "Resolving deltas: 100% (4033/4033), done.\n",
            "Updating files: 100% (309/309), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we try to filter the json objects, where\n",
        "\n",
        "\"langOrig\":\"eng\",\n",
        "\n",
        "e.g., /content/vd17-dump/json/vd17-290.json\n",
        "\n",
        "\tLine  6361:   \"langOrig\":\"eng\",\n",
        "\tLine 39193:   \"langOrig\":\"eng\",\n",
        "\n",
        "and write this to a separate file\n",
        "\n",
        "(ideally we try to create a separate language file for each langOrig value)\n",
        "\n",
        "https://stackoverflow.com/questions/27189892/how-to-filter-json-array-in-python\n"
      ],
      "metadata": {
        "id": "IRmlsilJxf6s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6ud8Bg7jYP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class to read the directory with json files and extract the needed language\n"
      ],
      "metadata": {
        "id": "2rKnvq20ew8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re, os, sys\n",
        "\n",
        "class clJsonDirFindFilter(object):\n",
        "    '''\n",
        "    @author Bogdan Babych, IÃœD, Heidelberg University, 2023\n",
        "    @email bogdan [dot] babych [at] iued [dot] uni-heidelberg [dot] de\n",
        "    '''\n",
        "    def __init__(self, SDirName, output_file = 'vdExtracted-all.json', debug_file = 'vdExtracted-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng'):\n",
        "        self.FOut = open(output_file, 'w')\n",
        "        self.FDebug = open(debug_file, 'w')\n",
        "        self.FDebugCounts = open(debug_file_02, 'w')\n",
        "\n",
        "        self.output_data = []\n",
        "        self.dictVals = {}\n",
        "\n",
        "        self.mainDirWalk(SDirName, findKey, filtVal)\n",
        "        output_list = self.filtByLang(self.output_data, findKey, filtVal)\n",
        "\n",
        "        self.dumpOutput(output_list, self.FOut)\n",
        "        print(len(self.dictVals))\n",
        "        self.printFrqDict(self.dictVals, self.FDebug)\n",
        "\n",
        "\n",
        "\n",
        "    def mainDirWalk(self, path, findKey, filtVal):\n",
        "\n",
        "        for root,d_names,f_names in os.walk(path):\n",
        "            for f in f_names:\n",
        "                # if not re.match('^[0-9]+$', f):\n",
        "                if not re.search('json$', f):\n",
        "                    print(f'Skipped: {f}')\n",
        "                    continue\n",
        "                fullpath = os.path.join(root, f)\n",
        "                self.procFile(fullpath, findKey, filtVal)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def procFile(self, SFIn, findKey, filtVal):\n",
        "        # output_data is a json list of dictionaries, which is updated with every json file read from the directory\n",
        "\n",
        "        with open(SFIn, 'r', encoding='utf-8') as input_json:\n",
        "            input_list = json.load(input_json)\n",
        "            countLO = 0\n",
        "            output_data_one_file = []\n",
        "            for i in input_list:\n",
        "                if findKey in i:\n",
        "                    countLO += 1\n",
        "\n",
        "                    langOrigValue = i[findKey]\n",
        "\n",
        "                    if langOrigValue not in self.dictVals:\n",
        "                        self.dictVals[langOrigValue] = 0\n",
        "                    self.dictVals[langOrigValue] += 1\n",
        "\n",
        "                    self.output_data.append(i)\n",
        "                    output_data_one_file.append(i)\n",
        "\n",
        "            output_list_one_file = list(filter(lambda x: x[findKey] == filtVal, output_data_one_file))\n",
        "            output_list_len_one_file = len(output_list_one_file)\n",
        "            self.FDebugCounts.write(f'{SFIn}\\t{countLO}\\t{output_list_len_one_file}\\n')\n",
        "\n",
        "    def filtByLang(self, output_data2filter, findKey, filtVal):\n",
        "        # output_list = [x for x in input_list if x['langOrig'] == 'eng']\n",
        "        output_list = list(filter(lambda x: x[findKey] == filtVal, output_data2filter))\n",
        "        return output_list\n",
        "\n",
        "\n",
        "    def dumpOutput(self, output_data2print, output_dict_file):\n",
        "        json.dump(output_data2print, output_dict_file, indent=4, ensure_ascii=False)\n",
        "        output_dict_file.flush()\n",
        "\n",
        "\n",
        "    def printFrqDict(self, DFrq2print, FOutput):\n",
        "        for key, val in sorted(DFrq2print.items(), key=lambda item: item[1], reverse=True):\n",
        "            FOutput.write(f'{key}\\t{val}\\n')\n",
        "        FOutput.flush()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # output_json_string = json.dumps(output_data)\n",
        "    ## json.dump(output_data, output_dict_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "# end: class clJsonDirFindFilter"
      ],
      "metadata": {
        "id": "XkEo5ac1lhdJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OJsonDirFindFilter = clJsonDirFindFilter('/content/vd17-dump/json')"
      ],
      "metadata": {
        "id": "X7mJptJhv5Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "OJsonDirFindFilter0 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-eng-all.json', debug_file = 'vdExtracted-eng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-eng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng')\n",
        "OJsonDirFindFilter1 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engFre-all.json', debug_file = 'vdExtracted-engFre-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engFre-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;fre')\n",
        "OJsonDirFindFilter2 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engDut-all.json', debug_file = 'vdExtracted-engDut-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engDut-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;dut')\n",
        "OJsonDirFindFilter3 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engIta-all.json', debug_file = 'vdExtracted-engIta-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engIta-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;ita')\n",
        "OJsonDirFindFilter4 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-latEng-all.json', debug_file = 'vdExtracted-latEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-latEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'lat;eng')\n",
        "'''\n",
        "\n",
        "OJsonDirFindFilter01 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-eng-all.json', debug_file = 'vdExtracted-eng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-eng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng')\n",
        "\n",
        "OJsonDirFindFilter02 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engFre-all.json', debug_file = 'vdExtracted-engFre-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engFre-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;fre')\n",
        "OJsonDirFindFilter03 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engDut-all.json', debug_file = 'vdExtracted-engDut-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engDut-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;dut')\n",
        "OJsonDirFindFilter04 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-FreEng-all.json', debug_file = 'vdExtracted-FreEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-FreEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'fre;eng')\n",
        "OJsonDirFindFilter05 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-DutEng-all.json', debug_file = 'vdExtracted-DutEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-DutEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'dut;eng')\n",
        "\n",
        "OJsonDirFindFilter06 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engIta-all.json', debug_file = 'vdExtracted-engIta-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engIta-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;ita')\n",
        "OJsonDirFindFilter07 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-latEng-all.json', debug_file = 'vdExtracted-latEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-latEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'lat;eng')\n",
        "OJsonDirFindFilter08 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-FreDutEng-all.json', debug_file = 'vdExtracted-FreDutEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-FreDutEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'fre;dut;eng')\n",
        "OJsonDirFindFilter09 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-EngFreDut-all.json', debug_file = 'vdExtracted-EngFreDut-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-EngFreDut-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;fre;dut')\n",
        "\n",
        "# fre;dut;eng\n",
        "# eng;fre;dut\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36Gw7mbrqdAz",
        "outputId": "ccfde8cb-91af-4ee9-8e1c-3bae21c5315e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -cvzf vdExtracted-langs.tgz *.json"
      ],
      "metadata": {
        "id": "5T-txH6LxoZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip vdExtracted-langs.zip *.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bwDHqpRxrU2",
        "outputId": "7ddaf795-5969-4a2a-dc22-29241322553c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: vdExtracted-DutEng-all.json (deflated 80%)\n",
            "  adding: vdExtracted-eng-all.json (deflated 86%)\n",
            "  adding: vdExtracted-engDut-all.json (deflated 81%)\n",
            "  adding: vdExtracted-engFre-all.json (deflated 80%)\n",
            "  adding: vdExtracted-EngFreDut-all.json (deflated 51%)\n",
            "  adding: vdExtracted-engIta-all.json (deflated 87%)\n",
            "  adding: vdExtracted-FreDutEng-all.json (deflated 68%)\n",
            "  adding: vdExtracted-FreEng-all.json (deflated 86%)\n",
            "  adding: vdExtracted-latEng-all.json (deflated 74%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 setting up the environment for download xml and converting to json\n",
        "\n",
        "We will try to download again the original xml for 17, check if it agrees with Dump, and then try to download 18, etc."
      ],
      "metadata": {
        "id": "Neb7mdYzvVTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nGyrrFQB_wdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1c8d26-0dd1-4e0e-d3ee-5744803c0e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pylib'...\n",
            "remote: Enumerating objects: 694, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 694 (delta 183), reused 162 (delta 77), pack-reused 424\u001b[K\n",
            "Receiving objects: 100% (694/694), 398.78 KiB | 2.68 MiB/s, done.\n",
            "Resolving deltas: 100% (448/448), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hbeyer/pylib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pylib/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT_ARX7WCpZt",
        "outputId": "82f184a7-9b79-4d6e-8113-a6c0f116da38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pylib\n",
            "/content/pylib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lib import bookwheel as bw"
      ],
      "metadata": {
        "id": "24QbZcLgIrCa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pickle\n",
        "from lib import sru\n",
        "from lib import isil\n",
        "from lib import xmlreader as xr\n",
        "from lib import pica"
      ],
      "metadata": {
        "id": "1Bk4apdcJmFb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s04uwOlgFccA",
        "outputId": "32c6556d-2fdc-4846-ab3e-afcc4969707b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "# from lib import bookwheel as bw\n",
        "cat = bw.Catalogue\n",
        "sec = cat.get_section(2589)\n",
        "print(sec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIn7UdSkAJuR",
        "outputId": "9651c310-60f3-4657-ec1d-4d978f268e86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'start': 2511, 'end': 2738, 'group': 'Libri Varii', 'dateBegin': '1634', 'year': 1634, 'writer': 'Herzog August'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir xmlbibliography\n",
        "!mkdir xmlbibliographyac"
      ],
      "metadata": {
        "id": "ffhaOHSALlvM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir jsonbibliography"
      ],
      "metadata": {
        "id": "1wXpb3u7M0Uw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUJJ1Ju5utQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 running the download script for RecordVD17"
      ],
      "metadata": {
        "id": "9OhpGVTVvBKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# import pickle\n",
        "# from lib import sru\n",
        "# from lib import isil\n",
        "# from lib import xmlreader as xr\n",
        "# from lib import pica\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# Festlegen der Speicherpfade und der DatensÃ¤tze pro JSON-Datei\n",
        "# source_folder = \"{Ordner mit den PICAXML-Dateien}/\"\n",
        "source_folder = \"/content/xmlbibliography/\"\n",
        "# source_folder_ac = \"{Ordner mit den PICAXML-Dateien fÃ¼r Gesamtaufnahmen mehrbÃ¤ndiger Werke (Ac-SÃ¤tze)}/\"\n",
        "source_folder_ac = \"/content/xmlbibliographyac/\"\n",
        "# target_folder = \"{Ordner zum Speichern der JSON-Dateien}/\"\n",
        "target_folder = \"/content/jsonbibliography/\"\n",
        "size = 1000\n",
        "limit = 350000\n",
        "\n",
        "# Laden der Ac-SÃ¤tze und Extrahieren der Gattungsbegriffe\n",
        "req = sru.Request_VD17()\n",
        "num = req.prepare(\"pica.bbg=Ac*\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder_ac)\n",
        "\n",
        "res = {}\n",
        "reader = xr.DownloadReader(source_folder_ac, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "for count, node in enumerate(reader):\n",
        "    rec = pica.RecordVD17(node)\n",
        "    gatt = [gat for gat in rec.gatt]\n",
        "    if gatt == []:\n",
        "        continue\n",
        "    res[rec.ppn] = gatt\n",
        "    if count > 100000:\n",
        "        break\n",
        "\n",
        "with open('gattungen-ac', 'wb') as file:\n",
        "    pickle.dump(res, file)\n",
        "\n",
        "# Download der PICA-XML-Daten\n",
        "req = sru.Request_VD17()\n",
        "num = req.prepare(\"pica.bbg=(Aa* or Af*)\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder)\n",
        "\n",
        "# Auslesen und Abspeichern in JSON\n",
        "with open('gattungen-ac','rb') as file:\n",
        "    gatt_ac = pickle.load(file)\n",
        "\n",
        "reader = xr.DownloadReader(source_folder, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "content = []\n",
        "fnn = []\n",
        "setn = 1\n",
        "count = 0\n",
        "\n",
        "for no, node in enumerate(reader):\n",
        "    rec = pica.RecordVD17(node)\n",
        "    if rec.get_rec_type() in [\"Teilband\", \"Teilband mit eigenem Titel\"]:\n",
        "        try:\n",
        "            rec.gatt = gatt_ac[rec.ppn_sup]\n",
        "        except:\n",
        "            logging.info(f\"Keine Gattungsbegriffe bei PPN {rec.ppn_sup}\")\n",
        "    content.append(rec)\n",
        "    count += 1\n",
        "    if count >= size:\n",
        "        recl = pica.RecordList(content)\n",
        "        fn = f\"vd17-{str(setn).zfill(3)}\"\n",
        "        recl.to_json(target_folder + fn)\n",
        "        content = []\n",
        "        setn += 1\n",
        "        count = 0\n",
        "    if no > limit:\n",
        "        break\n",
        "if content != []:\n",
        "    recl = pica.RecordList(content)\n",
        "    fn = f\"vd17-{str(setn).zfill(3)}\"\n",
        "    recl.to_json(target_folder + fn)\n"
      ],
      "metadata": {
        "id": "7F82KoohI6ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -cvzf xmlbibliography.tgz ./xmlbibliography"
      ],
      "metadata": {
        "id": "2gYgyX5r1qWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -cvzf jsonbibliography.tgz ./jsonbibliography"
      ],
      "metadata": {
        "id": "4yTuDQdZ2pCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting from downloaded json files (not the dump)\n",
        "now we need to extract data from the downloader repository, and check the statistics..."
      ],
      "metadata": {
        "id": "F-dsgPBE618e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OJsonDirFindFilter10 = clJsonDirFindFilter('/content/jsonbibliography', output_file = 'veExtracted-eng-all.json', debug_file = 'veExtracted-eng-debug-oriLangsAll.txt', debug_file_02 = 'veExtracted-eng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWMdFmiJ7E-d",
        "outputId": "6547758c-067f-4a31-e761-083076058c2d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing VD18 & VD16\n"
      ],
      "metadata": {
        "id": "3uf2iE_99BUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir xmlbibliography18\n",
        "!mkdir xmlbibliographyac18\n",
        "!mkdir jsonbibliography18"
      ],
      "metadata": {
        "id": "47ceja9p-g7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# import pickle\n",
        "# from lib import sru\n",
        "# from lib import isil\n",
        "# from lib import xmlreader as xr\n",
        "# from lib import pica\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# Festlegen der Speicherpfade und der DatensÃ¤tze pro JSON-Datei\n",
        "# source_folder = \"{Ordner mit den PICAXML-Dateien}/\"\n",
        "source_folder = \"/content/xmlbibliography18/\"\n",
        "# source_folder_ac = \"{Ordner mit den PICAXML-Dateien fÃ¼r Gesamtaufnahmen mehrbÃ¤ndiger Werke (Ac-SÃ¤tze)}/\"\n",
        "source_folder_ac = \"/content/xmlbibliographyac18/\"\n",
        "# target_folder = \"{Ordner zum Speichern der JSON-Dateien}/\"\n",
        "target_folder = \"/content/jsonbibliography18/\"\n",
        "size = 1000\n",
        "limit = 350000\n",
        "\n",
        "# Laden der Ac-SÃ¤tze und Extrahieren der Gattungsbegriffe\n",
        "req = sru.Request_VD18()\n",
        "num = req.prepare(\"pica.bbg=Ac*\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder_ac)\n",
        "\n",
        "res = {}\n",
        "reader = xr.DownloadReader(source_folder_ac, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "for count, node in enumerate(reader):\n",
        "    rec = pica.RecordVD18(node)\n",
        "    gatt = [gat for gat in rec.gatt]\n",
        "    if gatt == []:\n",
        "        continue\n",
        "    res[rec.ppn] = gatt\n",
        "    if count > 100000:\n",
        "        break\n",
        "\n",
        "with open('gattungen-ac', 'wb') as file:\n",
        "    pickle.dump(res, file)\n",
        "\n",
        "# Download der PICA-XML-Daten\n",
        "req = sru.Request_VD18()\n",
        "num = req.prepare(\"pica.bbg=(Aa* or Af*)\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder)\n",
        "\n",
        "# Auslesen und Abspeichern in JSON\n",
        "with open('gattungen-ac','rb') as file:\n",
        "    gatt_ac = pickle.load(file)\n",
        "\n",
        "reader = xr.DownloadReader(source_folder, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "content = []\n",
        "fnn = []\n",
        "setn = 1\n",
        "count = 0\n",
        "\n",
        "for no, node in enumerate(reader):\n",
        "    rec = pica.RecordVD18(node)\n",
        "    if rec.get_rec_type() in [\"Teilband\", \"Teilband mit eigenem Titel\"]:\n",
        "        try:\n",
        "            rec.gatt = gatt_ac[rec.ppn_sup]\n",
        "        except:\n",
        "            logging.info(f\"Keine Gattungsbegriffe bei PPN {rec.ppn_sup}\")\n",
        "    content.append(rec)\n",
        "    count += 1\n",
        "    if count >= size:\n",
        "        recl = pica.RecordList(content)\n",
        "        fn = f\"vd18-{str(setn).zfill(3)}\"\n",
        "        recl.to_json(target_folder + fn)\n",
        "        content = []\n",
        "        setn += 1\n",
        "        count = 0\n",
        "    if no > limit:\n",
        "        break\n",
        "if content != []:\n",
        "    recl = pica.RecordList(content)\n",
        "    fn = f\"vd18-{str(setn).zfill(3)}\"\n",
        "    recl.to_json(target_folder + fn)"
      ],
      "metadata": {
        "id": "0vucvD9O-jR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VD16 -- error (?)\n"
      ],
      "metadata": {
        "id": "voZxrfsu-pMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir xmlbibliography16\n",
        "!mkdir xmlbibliographyac16\n",
        "!mkdir jsonbibliography16"
      ],
      "metadata": {
        "id": "dMJ7glfH9GFk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# import pickle\n",
        "# from lib import sru\n",
        "# from lib import isil\n",
        "# from lib import xmlreader as xr\n",
        "# from lib import pica\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# Festlegen der Speicherpfade und der DatensÃ¤tze pro JSON-Datei\n",
        "# source_folder = \"{Ordner mit den PICAXML-Dateien}/\"\n",
        "source_folder = \"/content/xmlbibliography16/\"\n",
        "# source_folder_ac = \"{Ordner mit den PICAXML-Dateien fÃ¼r Gesamtaufnahmen mehrbÃ¤ndiger Werke (Ac-SÃ¤tze)}/\"\n",
        "source_folder_ac = \"/content/xmlbibliographyac16/\"\n",
        "# target_folder = \"{Ordner zum Speichern der JSON-Dateien}/\"\n",
        "target_folder = \"/content/jsonbibliography16/\"\n",
        "size = 1000\n",
        "limit = 350000\n",
        "\n",
        "# Laden der Ac-SÃ¤tze und Extrahieren der Gattungsbegriffe\n",
        "req = sru.Request_VD16()\n",
        "num = req.prepare(\"pica.bbg=Ac*\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder_ac)\n",
        "\n",
        "res = {}\n",
        "reader = xr.DownloadReader(source_folder_ac, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "for count, node in enumerate(reader):\n",
        "    rec = pica.RecordVD16(node)\n",
        "    gatt = [gat for gat in rec.gatt]\n",
        "    if gatt == []:\n",
        "        continue\n",
        "    res[rec.ppn] = gatt\n",
        "    if count > 100000:\n",
        "        break\n",
        "\n",
        "with open('gattungen-ac', 'wb') as file:\n",
        "    pickle.dump(res, file)\n",
        "\n",
        "# Download der PICA-XML-Daten\n",
        "req = sru.Request_VD16()\n",
        "num = req.prepare(\"pica.bbg=(Aa* or Af*)\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder)\n",
        "\n",
        "# Auslesen und Abspeichern in JSON\n",
        "with open('gattungen-ac','rb') as file:\n",
        "    gatt_ac = pickle.load(file)\n",
        "\n",
        "reader = xr.DownloadReader(source_folder, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "content = []\n",
        "fnn = []\n",
        "setn = 1\n",
        "count = 0\n",
        "\n",
        "for no, node in enumerate(reader):\n",
        "    rec = pica.RecordVD16(node)\n",
        "    if rec.get_rec_type() in [\"Teilband\", \"Teilband mit eigenem Titel\"]:\n",
        "        try:\n",
        "            rec.gatt = gatt_ac[rec.ppn_sup]\n",
        "        except:\n",
        "            logging.info(f\"Keine Gattungsbegriffe bei PPN {rec.ppn_sup}\")\n",
        "    content.append(rec)\n",
        "    count += 1\n",
        "    if count >= size:\n",
        "        recl = pica.RecordList(content)\n",
        "        fn = f\"vd16-{str(setn).zfill(3)}\"\n",
        "        recl.to_json(target_folder + fn)\n",
        "        content = []\n",
        "        setn += 1\n",
        "        count = 0\n",
        "    if no > limit:\n",
        "        break\n",
        "if content != []:\n",
        "    recl = pica.RecordList(content)\n",
        "    fn = f\"vd16-{str(setn).zfill(3)}\"\n",
        "    recl.to_json(target_folder + fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "ZZKeCwxm9VaY",
        "outputId": "215296b0-6adb-443c-c6bd-096d9dde651d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-81016c430553>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Laden der Ac-SÃ¤tze und Extrahieren der Gattungsbegriffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest_VD16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pica.bbg=Ac*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'lib.sru' has no attribute 'Request_VD16'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing commands - to be removed"
      ],
      "metadata": {
        "id": "iCJr9dNqu2TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd xmlbibliography/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qirpT0peL1h7",
        "outputId": "c767ddfe-a3b7-47f6-c845-a6b8a3f0cf6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/xmlbibliography\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB_MnmB_ASw5",
        "outputId": "309abc9c-d9de-468d-fb7b-7622b63eab55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"$/env/python\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s86IcciVHZW7",
        "outputId": "12ba24dc-e6e1-4da7-f7a3-b96f1ad9c31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PATH=\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPZelF_WIFWJ",
        "outputId": "27baf29e-7fc7-40ce-bbb1-23a5a86bb757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PATH=\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIiTbUU7Cm-2",
        "outputId": "5ee0b92e-2c0a-485d-97a7-0462d4dbb27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python:/content/pylib/lib/:/content/pylib/lib/bookwheel.py\"\n",
        "# !PYTHONPATH=. ./comet/cli/score.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfHI8zshAZc_",
        "outputId": "dcd3f04e-9b97-4428-872b-0ffc6155f40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python:/content/pylib/lib/:/content/pylib/lib/bookwheel.py\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!pwd"
      ],
      "metadata": {
        "id": "7QNOb_ahFZZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1049d3-88b3-41a4-d487-e97c1a90a79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://sru.k10plus.de/vd17?version=2.0&operation=searchRetrieve&query=pica.bbg=%28Aa*%20or%20Af*%29&maximumRecords=500&startRecord=1&recordSchema=picaxml"
      ],
      "metadata": {
        "id": "HAxwIMRYL4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv vd17?version=2.0 vd17_500.xml"
      ],
      "metadata": {
        "id": "D3xzAOeVMOlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDvJzrJVMWIG",
        "outputId": "1953d3b1-dbad-4568-c859-4ecb2ce5d003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    }
  ]
}