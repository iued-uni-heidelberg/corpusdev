{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSJ8hQIvgcwllo+LkMGbxb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpusdev/blob/main/bibliography_dataset_download_v05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting bibliography for the Y1600, Y1700, Y1800 periods from library catalogues"
      ],
      "metadata": {
        "id": "drKdxmEUvsEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 downloading the json dump of vd17\n",
        "This will last about 2 minutes, the command downloads 307 json files\n",
        "(such files should be generated on stage 2, see 2.1, etc. -- but there are differences between the dupm and the downloaded version)"
      ],
      "metadata": {
        "id": "mDyHA-rzvYx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://git.hab.de/beyer/vd17-dump/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqjkxzcUFmZF",
        "outputId": "afa10ea6-c8bf-4d3c-d91c-37bc8a8a06f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vd17-dump'...\n",
            "warning: redirecting to https://git.hab.de/beyer/vd17-dump.git/\n",
            "remote: Enumerating objects: 4739, done.\u001b[K\n",
            "remote: Counting objects: 100% (2862/2862), done.\u001b[K\n",
            "remote: Compressing objects: 100% (660/660), done.\u001b[K\n",
            "remote: Total 4739 (delta 2202), reused 2862 (delta 2202), pack-reused 1877\u001b[K\n",
            "Receiving objects: 100% (4739/4739), 646.03 MiB | 18.37 MiB/s, done.\n",
            "Resolving deltas: 100% (4033/4033), done.\n",
            "Updating files: 100% (309/309), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we try to filter the json objects, where\n",
        "\n",
        "\"langOrig\":\"eng\",\n",
        "\n",
        "e.g., /content/vd17-dump/json/vd17-290.json\n",
        "\n",
        "\tLine  6361:   \"langOrig\":\"eng\",\n",
        "\tLine 39193:   \"langOrig\":\"eng\",\n",
        "\n",
        "and write this to a separate file\n",
        "\n",
        "(ideally we try to create a separate language file for each langOrig value)\n",
        "\n",
        "https://stackoverflow.com/questions/27189892/how-to-filter-json-array-in-python\n"
      ],
      "metadata": {
        "id": "IRmlsilJxf6s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6ud8Bg7jYP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class to read the directory with json files and extract the needed language\n"
      ],
      "metadata": {
        "id": "2rKnvq20ew8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re, os, sys\n",
        "\n",
        "class clJsonDirFindFilter(object):\n",
        "    '''\n",
        "    @author Bogdan Babych, IÜD, Heidelberg University, 2023\n",
        "    @email bogdan [dot] babych [at] iued [dot] uni-heidelberg [dot] de\n",
        "    '''\n",
        "    def __init__(self, SDirName, output_file = 'vdExtracted-all.json', debug_file = 'vdExtracted-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng'):\n",
        "        self.FOut = open(output_file, 'w')\n",
        "        self.FDebug = open(debug_file, 'w')\n",
        "        self.FDebugCounts = open(debug_file_02, 'w')\n",
        "\n",
        "        self.output_data = []\n",
        "        self.dictVals = {}\n",
        "\n",
        "        self.mainDirWalk(SDirName, findKey, filtVal)\n",
        "        output_list = self.filtByLang(self.output_data, findKey, filtVal)\n",
        "\n",
        "        self.dumpOutput(output_list, self.FOut)\n",
        "        print(len(self.dictVals))\n",
        "        self.printFrqDict(self.dictVals, self.FDebug)\n",
        "\n",
        "\n",
        "\n",
        "    def mainDirWalk(self, path, findKey, filtVal):\n",
        "\n",
        "        for root,d_names,f_names in os.walk(path):\n",
        "            for f in f_names:\n",
        "                # if not re.match('^[0-9]+$', f):\n",
        "                if not re.search('json$', f):\n",
        "                    print(f'Skipped: {f}')\n",
        "                    continue\n",
        "                fullpath = os.path.join(root, f)\n",
        "                self.procFile(fullpath, findKey, filtVal)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def procFile(self, SFIn, findKey, filtVal):\n",
        "        # output_data is a json list of dictionaries, which is updated with every json file read from the directory\n",
        "\n",
        "        with open(SFIn, 'r', encoding='utf-8') as input_json:\n",
        "            input_list = json.load(input_json)\n",
        "            countLO = 0\n",
        "            output_data_one_file = []\n",
        "            for i in input_list:\n",
        "                if findKey in i:\n",
        "                    countLO += 1\n",
        "\n",
        "                    langOrigValue = i[findKey]\n",
        "\n",
        "                    if langOrigValue not in self.dictVals:\n",
        "                        self.dictVals[langOrigValue] = 0\n",
        "                    self.dictVals[langOrigValue] += 1\n",
        "\n",
        "                    self.output_data.append(i)\n",
        "                    output_data_one_file.append(i)\n",
        "\n",
        "            output_list_one_file = list(filter(lambda x: x[findKey] == filtVal, output_data_one_file))\n",
        "            output_list_len_one_file = len(output_list_one_file)\n",
        "            self.FDebugCounts.write(f'{SFIn}\\t{countLO}\\t{output_list_len_one_file}\\n')\n",
        "\n",
        "    def filtByLang(self, output_data2filter, findKey, filtVal):\n",
        "        # output_list = [x for x in input_list if x['langOrig'] == 'eng']\n",
        "        output_list = list(filter(lambda x: x[findKey] == filtVal, output_data2filter))\n",
        "        return output_list\n",
        "\n",
        "\n",
        "    def dumpOutput(self, output_data2print, output_dict_file):\n",
        "        json.dump(output_data2print, output_dict_file, indent=4, ensure_ascii=False)\n",
        "        output_dict_file.flush()\n",
        "\n",
        "\n",
        "    def printFrqDict(self, DFrq2print, FOutput):\n",
        "        for key, val in sorted(DFrq2print.items(), key=lambda item: item[1], reverse=True):\n",
        "            FOutput.write(f'{key}\\t{val}\\n')\n",
        "        FOutput.flush()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # output_json_string = json.dumps(output_data)\n",
        "    ## json.dump(output_data, output_dict_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "# end: class clJsonDirFindFilter"
      ],
      "metadata": {
        "id": "XkEo5ac1lhdJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OJsonDirFindFilter = clJsonDirFindFilter('/content/vd17-dump/json')"
      ],
      "metadata": {
        "id": "X7mJptJhv5Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "OJsonDirFindFilter0 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-eng-all.json', debug_file = 'vdExtracted-eng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-eng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng')\n",
        "OJsonDirFindFilter1 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engFre-all.json', debug_file = 'vdExtracted-engFre-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engFre-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;fre')\n",
        "OJsonDirFindFilter2 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engDut-all.json', debug_file = 'vdExtracted-engDut-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engDut-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;dut')\n",
        "OJsonDirFindFilter3 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engIta-all.json', debug_file = 'vdExtracted-engIta-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engIta-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;ita')\n",
        "OJsonDirFindFilter4 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-latEng-all.json', debug_file = 'vdExtracted-latEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-latEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'lat;eng')\n",
        "'''\n",
        "\n",
        "OJsonDirFindFilter01 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-eng-all.json', debug_file = 'vdExtracted-eng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-eng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng')\n",
        "\n",
        "OJsonDirFindFilter02 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engFre-all.json', debug_file = 'vdExtracted-engFre-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engFre-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;fre')\n",
        "OJsonDirFindFilter03 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engDut-all.json', debug_file = 'vdExtracted-engDut-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engDut-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;dut')\n",
        "OJsonDirFindFilter04 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-FreEng-all.json', debug_file = 'vdExtracted-FreEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-FreEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'fre;eng')\n",
        "OJsonDirFindFilter05 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-DutEng-all.json', debug_file = 'vdExtracted-DutEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-DutEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'dut;eng')\n",
        "\n",
        "OJsonDirFindFilter06 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-engIta-all.json', debug_file = 'vdExtracted-engIta-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-engIta-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;ita')\n",
        "OJsonDirFindFilter07 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-latEng-all.json', debug_file = 'vdExtracted-latEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-latEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'lat;eng')\n",
        "OJsonDirFindFilter08 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-FreDutEng-all.json', debug_file = 'vdExtracted-FreDutEng-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-FreDutEng-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'fre;dut;eng')\n",
        "OJsonDirFindFilter09 = clJsonDirFindFilter('/content/vd17-dump/json', output_file = 'vdExtracted-EngFreDut-all.json', debug_file = 'vdExtracted-EngFreDut-debug-oriLangsAll.txt', debug_file_02 = 'vdExtracted-EngFreDut-debug-sourceFileCounts.txt', findKey = 'langOrig', filtVal = 'eng;fre;dut')\n",
        "\n",
        "# fre;dut;eng\n",
        "# eng;fre;dut\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36Gw7mbrqdAz",
        "outputId": "ccfde8cb-91af-4ee9-8e1c-3bae21c5315e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n",
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -cvzf vdExtracted-langs.tgz *.json"
      ],
      "metadata": {
        "id": "5T-txH6LxoZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip vdExtracted-langs.zip *.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bwDHqpRxrU2",
        "outputId": "7ddaf795-5969-4a2a-dc22-29241322553c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: vdExtracted-DutEng-all.json (deflated 80%)\n",
            "  adding: vdExtracted-eng-all.json (deflated 86%)\n",
            "  adding: vdExtracted-engDut-all.json (deflated 81%)\n",
            "  adding: vdExtracted-engFre-all.json (deflated 80%)\n",
            "  adding: vdExtracted-EngFreDut-all.json (deflated 51%)\n",
            "  adding: vdExtracted-engIta-all.json (deflated 87%)\n",
            "  adding: vdExtracted-FreDutEng-all.json (deflated 68%)\n",
            "  adding: vdExtracted-FreEng-all.json (deflated 86%)\n",
            "  adding: vdExtracted-latEng-all.json (deflated 74%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 setting up the environment for download xml and converting to json\n",
        "\n",
        "We will try to download again the original xml for 17, check if it agrees with Dump, and then try to download 18, etc."
      ],
      "metadata": {
        "id": "Neb7mdYzvVTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nGyrrFQB_wdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1c8d26-0dd1-4e0e-d3ee-5744803c0e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pylib'...\n",
            "remote: Enumerating objects: 694, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 694 (delta 183), reused 162 (delta 77), pack-reused 424\u001b[K\n",
            "Receiving objects: 100% (694/694), 398.78 KiB | 2.68 MiB/s, done.\n",
            "Resolving deltas: 100% (448/448), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hbeyer/pylib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pylib/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT_ARX7WCpZt",
        "outputId": "82f184a7-9b79-4d6e-8113-a6c0f116da38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pylib\n",
            "/content/pylib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lib import bookwheel as bw"
      ],
      "metadata": {
        "id": "24QbZcLgIrCa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pickle\n",
        "from lib import sru\n",
        "from lib import isil\n",
        "from lib import xmlreader as xr\n",
        "from lib import pica"
      ],
      "metadata": {
        "id": "1Bk4apdcJmFb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s04uwOlgFccA",
        "outputId": "32c6556d-2fdc-4846-ab3e-afcc4969707b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "# from lib import bookwheel as bw\n",
        "cat = bw.Catalogue\n",
        "sec = cat.get_section(2589)\n",
        "print(sec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIn7UdSkAJuR",
        "outputId": "9651c310-60f3-4657-ec1d-4d978f268e86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'start': 2511, 'end': 2738, 'group': 'Libri Varii', 'dateBegin': '1634', 'year': 1634, 'writer': 'Herzog August'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir xmlbibliography\n",
        "!mkdir xmlbibliographyac"
      ],
      "metadata": {
        "id": "ffhaOHSALlvM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir jsonbibliography"
      ],
      "metadata": {
        "id": "1wXpb3u7M0Uw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUJJ1Ju5utQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 running the download script for RecordVD17"
      ],
      "metadata": {
        "id": "9OhpGVTVvBKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# import pickle\n",
        "# from lib import sru\n",
        "# from lib import isil\n",
        "# from lib import xmlreader as xr\n",
        "# from lib import pica\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# Festlegen der Speicherpfade und der Datensätze pro JSON-Datei\n",
        "# source_folder = \"{Ordner mit den PICAXML-Dateien}/\"\n",
        "source_folder = \"/content/xmlbibliography/\"\n",
        "# source_folder_ac = \"{Ordner mit den PICAXML-Dateien für Gesamtaufnahmen mehrbändiger Werke (Ac-Sätze)}/\"\n",
        "source_folder_ac = \"/content/xmlbibliography/\"\n",
        "# target_folder = \"{Ordner zum Speichern der JSON-Dateien}/\"\n",
        "target_folder = \"/content/jsonbibliography/\"\n",
        "size = 1000\n",
        "limit = 350000\n",
        "\n",
        "# Laden der Ac-Sätze und Extrahieren der Gattungsbegriffe\n",
        "req = sru.Request_VD17()\n",
        "num = req.prepare(\"pica.bbg=Ac*\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder_ac)\n",
        "\n",
        "res = {}\n",
        "reader = xr.DownloadReader(source_folder_ac, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "for count, node in enumerate(reader):\n",
        "    rec = pica.RecordVD17(node)\n",
        "    gatt = [gat for gat in rec.gatt]\n",
        "    if gatt == []:\n",
        "        continue\n",
        "    res[rec.ppn] = gatt\n",
        "    if count > 100000:\n",
        "        break\n",
        "\n",
        "with open('gattungen-ac', 'wb') as file:\n",
        "    pickle.dump(res, file)\n",
        "\n",
        "# Download der PICA-XML-Daten\n",
        "req = sru.Request_VD17()\n",
        "num = req.prepare(\"pica.bbg=(Aa* or Af*)\")\n",
        "print(req.url)\n",
        "print(req.numFound)\n",
        "req.download(source_folder)\n",
        "\n",
        "# Auslesen und Abspeichern in JSON\n",
        "with open('gattungen-ac','rb') as file:\n",
        "    gatt_ac = pickle.load(file)\n",
        "\n",
        "reader = xr.DownloadReader(source_folder, \"record\", \"info:srw/schema/5/picaXML-v1.0\")\n",
        "\n",
        "content = []\n",
        "fnn = []\n",
        "setn = 1\n",
        "count = 0\n",
        "\n",
        "for no, node in enumerate(reader):\n",
        "    rec = pica.RecordVD17(node)\n",
        "    if rec.get_rec_type() in [\"Teilband\", \"Teilband mit eigenem Titel\"]:\n",
        "        try:\n",
        "            rec.gatt = gatt_ac[rec.ppn_sup]\n",
        "        except:\n",
        "            logging.info(f\"Keine Gattungsbegriffe bei PPN {rec.ppn_sup}\")\n",
        "    content.append(rec)\n",
        "    count += 1\n",
        "    if count >= size:\n",
        "        recl = pica.RecordList(content)\n",
        "        fn = f\"vd17-{str(setn).zfill(3)}\"\n",
        "        recl.to_json(target_folder + fn)\n",
        "        content = []\n",
        "        setn += 1\n",
        "        count = 0\n",
        "    if no > limit:\n",
        "        break\n",
        "if content != []:\n",
        "    recl = pica.RecordList(content)\n",
        "    fn = f\"vd17-{str(setn).zfill(3)}\"\n",
        "    recl.to_json(target_folder + fn)\n"
      ],
      "metadata": {
        "id": "7F82KoohI6ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b00eb56-8ecf-4bad-8b2a-c9d4ab8e5e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://sru.k10plus.de/vd17?version=2.0&operation=searchRetrieve&query=pica.bbg%3DAc%2A&maximumRecords=500&startRecord=1&recordSchema=picaxml\n",
            "5088\n",
            "Download 1 erledigt\n",
            "Download 2 erledigt\n",
            "Download 3 erledigt\n",
            "Download 4 erledigt\n",
            "Download 5 erledigt\n",
            "Download 6 erledigt\n",
            "Download 7 erledigt\n",
            "Download 8 erledigt\n",
            "Download 9 erledigt\n",
            "Download 10 erledigt\n",
            "Download 11 erledigt\n",
            "http://sru.k10plus.de/vd17?version=2.0&operation=searchRetrieve&query=pica.bbg%3D%28Aa%2A%20or%20Af%2A%29&maximumRecords=500&startRecord=1&recordSchema=picaxml\n",
            "307329\n",
            "Download 1 erledigt\n",
            "Download 2 erledigt\n",
            "Download 3 erledigt\n",
            "Download 4 erledigt\n",
            "Download 5 erledigt\n",
            "Download 6 erledigt\n",
            "Download 7 erledigt\n",
            "Download 8 erledigt\n",
            "Download 9 erledigt\n",
            "Download 10 erledigt\n",
            "Download 11 erledigt\n",
            "Download 12 erledigt\n",
            "Download 13 erledigt\n",
            "Download 14 erledigt\n",
            "Download 15 erledigt\n",
            "Download 16 erledigt\n",
            "Download 17 erledigt\n",
            "Download 18 erledigt\n",
            "Download 19 erledigt\n",
            "Download 20 erledigt\n",
            "Download 21 erledigt\n",
            "Download 22 erledigt\n",
            "Download 23 erledigt\n",
            "Download 24 erledigt\n",
            "Download 25 erledigt\n",
            "Download 26 erledigt\n",
            "Download 27 erledigt\n",
            "Download 28 erledigt\n",
            "Download 29 erledigt\n",
            "Download 30 erledigt\n",
            "Download 31 erledigt\n",
            "Download 32 erledigt\n",
            "Download 33 erledigt\n",
            "Download 34 erledigt\n",
            "Download 35 erledigt\n",
            "Download 36 erledigt\n",
            "Download 37 erledigt\n",
            "Download 38 erledigt\n",
            "Download 39 erledigt\n",
            "Download 40 erledigt\n",
            "Download 41 erledigt\n",
            "Download 42 erledigt\n",
            "Download 43 erledigt\n",
            "Download 44 erledigt\n",
            "Download 45 erledigt\n",
            "Download 46 erledigt\n",
            "Download 47 erledigt\n",
            "Download 48 erledigt\n",
            "Download 49 erledigt\n",
            "Download 50 erledigt\n",
            "Download 51 erledigt\n",
            "Download 52 erledigt\n",
            "Download 53 erledigt\n",
            "Download 54 erledigt\n",
            "Download 55 erledigt\n",
            "Download 56 erledigt\n",
            "Download 57 erledigt\n",
            "Download 58 erledigt\n",
            "Download 59 erledigt\n",
            "Download 60 erledigt\n",
            "Download 61 erledigt\n",
            "Download 62 erledigt\n",
            "Download 63 erledigt\n",
            "Download 64 erledigt\n",
            "Download 65 erledigt\n",
            "Download 66 erledigt\n",
            "Download 67 erledigt\n",
            "Download 68 erledigt\n",
            "Download 69 erledigt\n",
            "Download 70 erledigt\n",
            "Download 71 erledigt\n",
            "Download 72 erledigt\n",
            "Download 73 erledigt\n",
            "Download 74 erledigt\n",
            "Download 75 erledigt\n",
            "Download 76 erledigt\n",
            "Download 77 erledigt\n",
            "Download 78 erledigt\n",
            "Download 79 erledigt\n",
            "Download 80 erledigt\n",
            "Download 81 erledigt\n",
            "Download 82 erledigt\n",
            "Download 83 erledigt\n",
            "Download 84 erledigt\n",
            "Download 85 erledigt\n",
            "Download 86 erledigt\n",
            "Download 87 erledigt\n",
            "Download 88 erledigt\n",
            "Download 89 erledigt\n",
            "Download 90 erledigt\n",
            "Download 91 erledigt\n",
            "Download 92 erledigt\n",
            "Download 93 erledigt\n",
            "Download 94 erledigt\n",
            "Download 95 erledigt\n",
            "Download 96 erledigt\n",
            "Download 97 erledigt\n",
            "Download 98 erledigt\n",
            "Download 99 erledigt\n",
            "Download 100 erledigt\n",
            "Download 101 erledigt\n",
            "Download 102 erledigt\n",
            "Download 103 erledigt\n",
            "Download 104 erledigt\n",
            "Download 105 erledigt\n",
            "Download 106 erledigt\n",
            "Download 107 erledigt\n",
            "Download 108 erledigt\n",
            "Download 109 erledigt\n",
            "Download 110 erledigt\n",
            "Download 111 erledigt\n",
            "Download 112 erledigt\n",
            "Download 113 erledigt\n",
            "Download 114 erledigt\n",
            "Download 115 erledigt\n",
            "Download 116 erledigt\n",
            "Download 117 erledigt\n",
            "Download 118 erledigt\n",
            "Download 119 erledigt\n",
            "Download 120 erledigt\n",
            "Download 121 erledigt\n",
            "Download 122 erledigt\n",
            "Download 123 erledigt\n",
            "Download 124 erledigt\n",
            "Download 125 erledigt\n",
            "Download 126 erledigt\n",
            "Download 127 erledigt\n",
            "Download 128 erledigt\n",
            "Download 129 erledigt\n",
            "Download 130 erledigt\n",
            "Download 131 erledigt\n",
            "Download 132 erledigt\n",
            "Download 133 erledigt\n",
            "Download 134 erledigt\n",
            "Download 135 erledigt\n",
            "Download 136 erledigt\n",
            "Download 137 erledigt\n",
            "Download 138 erledigt\n",
            "Download 139 erledigt\n",
            "Download 140 erledigt\n",
            "Download 141 erledigt\n",
            "Download 142 erledigt\n",
            "Download 143 erledigt\n",
            "Download 144 erledigt\n",
            "Download 145 erledigt\n",
            "Download 146 erledigt\n",
            "Download 147 erledigt\n",
            "Download 148 erledigt\n",
            "Download 149 erledigt\n",
            "Download 150 erledigt\n",
            "Download 151 erledigt\n",
            "Download 152 erledigt\n",
            "Download 153 erledigt\n",
            "Download 154 erledigt\n",
            "Download 155 erledigt\n",
            "Download 156 erledigt\n",
            "Download 157 erledigt\n",
            "Download 158 erledigt\n",
            "Download 159 erledigt\n",
            "Download 160 erledigt\n",
            "Download 161 erledigt\n",
            "Download 162 erledigt\n",
            "Download 163 erledigt\n",
            "Download 164 erledigt\n",
            "Download 165 erledigt\n",
            "Download 166 erledigt\n",
            "Download 167 erledigt\n",
            "Download 168 erledigt\n",
            "Download 169 erledigt\n",
            "Download 170 erledigt\n",
            "Download 171 erledigt\n",
            "Download 172 erledigt\n",
            "Download 173 erledigt\n",
            "Download 174 erledigt\n",
            "Download 175 erledigt\n",
            "Download 176 erledigt\n",
            "Download 177 erledigt\n",
            "Download 178 erledigt\n",
            "Download 179 erledigt\n",
            "Download 180 erledigt\n",
            "Download 181 erledigt\n",
            "Download 182 erledigt\n",
            "Download 183 erledigt\n",
            "Download 184 erledigt\n",
            "Download 185 erledigt\n",
            "Download 186 erledigt\n",
            "Download 187 erledigt\n",
            "Download 188 erledigt\n",
            "Download 189 erledigt\n",
            "Download 190 erledigt\n",
            "Download 191 erledigt\n",
            "Download 192 erledigt\n",
            "Download 193 erledigt\n",
            "Download 194 erledigt\n",
            "Download 195 erledigt\n",
            "Download 196 erledigt\n",
            "Download 197 erledigt\n",
            "Download 198 erledigt\n",
            "Download 199 erledigt\n",
            "Download 200 erledigt\n",
            "Download 201 erledigt\n",
            "Download 202 erledigt\n",
            "Download 203 erledigt\n",
            "Download 204 erledigt\n",
            "Download 205 erledigt\n",
            "Download 206 erledigt\n",
            "Download 207 erledigt\n",
            "Download 208 erledigt\n",
            "Download 209 erledigt\n",
            "Download 210 erledigt\n",
            "Download 211 erledigt\n",
            "Download 212 erledigt\n",
            "Download 213 erledigt\n",
            "Download 214 erledigt\n",
            "Download 215 erledigt\n",
            "Download 216 erledigt\n",
            "Download 217 erledigt\n",
            "Download 218 erledigt\n",
            "Download 219 erledigt\n",
            "Download 220 erledigt\n",
            "Download 221 erledigt\n",
            "Download 222 erledigt\n",
            "Download 223 erledigt\n",
            "Download 224 erledigt\n",
            "Download 225 erledigt\n",
            "Download 226 erledigt\n",
            "Download 227 erledigt\n",
            "Download 228 erledigt\n",
            "Download 229 erledigt\n",
            "Download 230 erledigt\n",
            "Download 231 erledigt\n",
            "Download 232 erledigt\n",
            "Download 233 erledigt\n",
            "Download 234 erledigt\n",
            "Download 235 erledigt\n",
            "Download 236 erledigt\n",
            "Download 237 erledigt\n",
            "Download 238 erledigt\n",
            "Download 239 erledigt\n",
            "Download 240 erledigt\n",
            "Download 241 erledigt\n",
            "Download 242 erledigt\n",
            "Download 243 erledigt\n",
            "Download 244 erledigt\n",
            "Download 245 erledigt\n",
            "Download 246 erledigt\n",
            "Download 247 erledigt\n",
            "Download 248 erledigt\n",
            "Download 249 erledigt\n",
            "Download 250 erledigt\n",
            "Download 251 erledigt\n",
            "Download 252 erledigt\n",
            "Download 253 erledigt\n",
            "Download 254 erledigt\n",
            "Download 255 erledigt\n",
            "Download 256 erledigt\n",
            "Download 257 erledigt\n",
            "Download 258 erledigt\n",
            "Download 259 erledigt\n",
            "Download 260 erledigt\n",
            "Download 261 erledigt\n",
            "Download 262 erledigt\n",
            "Download 263 erledigt\n",
            "Download 264 erledigt\n",
            "Download 265 erledigt\n",
            "Download 266 erledigt\n",
            "Download 267 erledigt\n",
            "Download 268 erledigt\n",
            "Download 269 erledigt\n",
            "Download 270 erledigt\n",
            "Download 271 erledigt\n",
            "Download 272 erledigt\n",
            "Download 273 erledigt\n",
            "Download 274 erledigt\n",
            "Download 275 erledigt\n",
            "Download 276 erledigt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -cvzf xmlbibliography.tgz ./xmlbibliography"
      ],
      "metadata": {
        "id": "2gYgyX5r1qWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing commands - to be removed"
      ],
      "metadata": {
        "id": "iCJr9dNqu2TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd xmlbibliography/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qirpT0peL1h7",
        "outputId": "c767ddfe-a3b7-47f6-c845-a6b8a3f0cf6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/xmlbibliography\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB_MnmB_ASw5",
        "outputId": "309abc9c-d9de-468d-fb7b-7622b63eab55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"$/env/python\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s86IcciVHZW7",
        "outputId": "12ba24dc-e6e1-4da7-f7a3-b96f1ad9c31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PATH=\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPZelF_WIFWJ",
        "outputId": "27baf29e-7fc7-40ce-bbb1-23a5a86bb757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PATH=\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/pylib/lib\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIiTbUU7Cm-2",
        "outputId": "5ee0b92e-2c0a-485d-97a7-0462d4dbb27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python:/content/pylib/lib/:/content/pylib/lib/bookwheel.py\"\n",
        "# !PYTHONPATH=. ./comet/cli/score.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfHI8zshAZc_",
        "outputId": "dcd3f04e-9b97-4428-872b-0ffc6155f40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python:/content/pylib/lib/:/content/pylib/lib/bookwheel.py\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!pwd"
      ],
      "metadata": {
        "id": "7QNOb_ahFZZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1049d3-88b3-41a4-d487-e97c1a90a79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://sru.k10plus.de/vd17?version=2.0&operation=searchRetrieve&query=pica.bbg=%28Aa*%20or%20Af*%29&maximumRecords=500&startRecord=1&recordSchema=picaxml"
      ],
      "metadata": {
        "id": "HAxwIMRYL4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv vd17?version=2.0 vd17_500.xml"
      ],
      "metadata": {
        "id": "D3xzAOeVMOlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDvJzrJVMWIG",
        "outputId": "1953d3b1-dbad-4568-c859-4ecb2ce5d003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    }
  ]
}